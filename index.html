<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
<link rel="stylesheet" type="text/css" href="static/base.css">
<link href='http://fonts.googleapis.com/css?family=Lato' rel='stylesheet' type='text/css'>
<!--<script type="text/javascript" src="index.js"></script>-->
<style>
html {
--theme-color: #003262;
}
</style>

<style>
#title .titledivider {
display: none;
}
</style>

<title>HuthLab </title>
</head>
<body>
<div id='header'>
<div id='title'>HuthLab <span class='titledivider'>|</span> <span class='titlesub'></span></div>
<div id='nav'>
<ul>

<li><a href=index.html>home</a></li>

<li><a href=people.html>people</a></li>

<li><a href=research.html>research</a></li>

<li><a href=publications.html>publications</a></li>

</ul>
</div>
</div>
<div id='content'>

<p>
Our lab uses quantitative, computational methods to try to understand how the human brain processes the natural world. In particular, we are focused on understanding how the meaning of language is represented in the brain.
</p>
<p>
Using fMRI, we record human brain responses while people listen to speech in the form of stories or podcasts.
Then we build <b>encoding models</b> that predict those responses based on the audio and transcript of the stories.
The best encoding models today use <b>neural network language models</b> to extract meaningful information from the stories.
Our work uses encoding models to map how language is represented across the brain <a href="http://papers.nips.cc/paper/7897-incorporating-context-into-language-encoding-models-for-fmri.pdf">[Jain et al., 2018,</a><a href="https://proceedings.neurips.cc//paper/2020/hash/9e9a30b74c49d07d8150c8c83b1ccf07-Abstract.html"> 2020;</a><a href="https://proceedings.neurips.cc/paper/2021/hash/464074179972cbbd75a39abc6954cd12-Abstract.html"> Antonello et al., 2021]</a>,
investigates why neural network language models are so effective <a href="http://dx.doi.org/10.1162/nol_a_00087">[Antonello & Huth, 2023]</a>,
and shows that we can even decode language from fMRI <a href="https://www.biorxiv.org/content/10.1101/2022.09.29.509744v1">[Tang et al., 2023]</a>.
</p>
<p>
The datasets we collect are <a href="https://openneuro.org/datasets/ds003020/versions/1.0.2">shared freely</a> and we encourage you to use them <a href="http://dx.doi.org/10.1101/2022.09.22.509104">[LeBel et al., 2022]</a>.
</p>
<p>
We also <a href="https://github.com/HuthLab/deep-fMRI-dataset">share code</a> that demonstrates how to use these datasets and <a href="https://github.com/HuthLab/speechmodeltutorial">tutorials</a> on encoding models for language.
</p>
<div class='divider'></div>
<div class='subheading'>Latest Publications</div>

<p class='pub'>Tang, Jerry and Huth, Alexander G (2025). <strong>Semantic language decoding across participants and stimulus modalities</strong>.
<em>Current Biology</em>.
doi: <a href='http://dx.doi.org/10.1016/j.cub.2025.01.024'>10.1016/j.cub.2025.01.024</a>




</p>


<p class='pub'>Abdel-Ghaffar, Samy A and Huth, Alexander G and Lescroart, Mark D and Stansbury, Dustin and Gallant, Jack L and Bishop, Sonia J (2024). <strong>Occipital-temporal cortical tuning to semantic and affective features of natural images predicts associated behavioral responses</strong>.
<em>Nature communications</em>.
doi: <a href='http://dx.doi.org/10.1016/j.cub.2025.01.024'>10.1016/j.cub.2025.01.024</a>




</p>


<p class='pub'>Vinamra Benara and Chandan Singh and John Xavier Morris and Richard Antonello and Ion Stoica and Alexander Huth and Jianfeng Gao (2024). <strong>Crafting Interpretable Embeddings for Language Neuroscience by Asking LLMs Questions</strong>.
<em>Advances in Neural Information Processing Systems</em>.
<a href='https://openreview.net/forum?id=mxMvWwyBWe'>(paper)</a> 


 <a href='https://github.com/csinva/interpretable-embeddings'>(GitHub)</a> 
</p>



</div>
<div id='footer'>
<div class='left'>
<div>University of California, Berkeley</div>
<ul>
<li><a href='http://berkeley.edu'>UCB Home</a></li>
<li><a href='https://neuroscience.berkeley.edu/'>UCB Neuroscience</a></li>
<li><a href='https://statistics.berkeley.edu/'>UCB Statistics</a></li>
</ul>
</div>
<div class='right'>
<div>Contact</div>
<ul>
<li><a href='mailto:alex.huth@berkeley.edu'>Email</a></li>
<li><a href='https://twitter.com/huthlab'>Twitter</a></li>
</ul>
</div>
 
<div id='copyright'>&copy; Huth Lab | University of California, Berkeley</div>
</div>
</body>
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', , 'auto');
ga('send', 'pageview');
</script>
</html>
